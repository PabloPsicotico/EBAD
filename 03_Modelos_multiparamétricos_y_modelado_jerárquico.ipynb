{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "palette = 'colorblind'\n",
    "sns.set_palette(palette); sns.set_color_codes(palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modelos Multiparamétricos y Modelado jerárquico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los capítulos previos aprendimos sobre los conceptos centrales de la estadística Bayesiana. En este capítulo veremos como crear y analizar modelos con más de un parámetro y estudiaremos como generar modelos jerárquicos, es decir modelos donde unos parámetros dependen de otros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Modelos Multiparamétricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prácticamente todos los modelos de interés en estadística, son multiparamétricos, es decir modelos con más de un parámetro. \n",
    "\n",
    "Suele suceder que no todos los parámetros requeridos para construir un modelo son de interés, supongamos que quisiéramos estimar el valor medio de una distribución Gaussiana, a menos que sepamos el valor _real_ de la desviación estándar, nuestro modelo deberá contener un parámetro para la media y uno para la desviación estándar. Los parámetros que no son de inmediato interés pero son necesarios para construir nuestros modelos se llaman _nuisance parameters_ (o parámetro estorbo).\n",
    "\n",
    "Recordemos que en estadística Bayesiana todos los parámetros tienen el mismo estatus, por lo que la diferencia entre _nuisance_ o no _nuisance_ no es fundamental bajo ningún concepto, si no que depende completamente de nuestras preguntas.\n",
    "\n",
    "En principio podría parecer que incorporar parámetros que no nos interesan es un ejercicio de futilidad. Sin embargo, es todo lo contrario, al incorporar estos parámetros permitimos que la incertidumbre que tenemos sobre ellos se propaguen de forma adecuada a los resultados.\n",
    "\n",
    "En términos generales un modelo con dos parámetros será algo como:\n",
    "\n",
    "$$P(\\theta_1, \\theta_2|y) \\propto P(y|\\theta_1, \\theta_2) P(\\theta_1, \\theta_2)$$\n",
    "\n",
    "lo que facilmente se puede generalizar a un modelo de más de dos parámetros. La principal diferencia con lo que ya habíamos visto es que ahora el _a posteriori_ será bidimensional (asumiendo que $\\theta_1$, $\\theta_2$ son escalares y no vectores).\n",
    "\n",
    "Supongamos por un momento que $\\theta_2$ no nos interesa realmente ¿Como hacemos entonces para expresar el _a posteriori_ solo en términos de $\\theta_1$? Lo que debemos hacer es obtener la distribución marginal del _a posteriori_ respecto del parámetro de interés. Matemáticamente esto es:\n",
    "\n",
    "$$P(\\theta_1|y) = \\int P(\\theta_1, \\theta_2|y) d\\theta_2$$\n",
    "\n",
    "Es decir integramosel _a posteriori_ sobre todos los valores posibles de los parámetros que no nos interesan inmediatamente. Para el caso de variables discretas la integral se convierte en una suma.\n",
    "\n",
    "En la siguiente figura se puede observar tres distribuciones. La distribución conjunta de $\\theta_1$ y $\\theta_2$ (_joint distribution_) en el centro. Y las distribuciones marginales de $\\theta_1$ en el _margen_ superior y de $\\theta_2$ en el _margen_ derecho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "x = np.random.normal(0, 2, 500)\n",
    "y = np.random.beta(1, 5, 500)\n",
    "x_name, y_name = 'θ1', 'θ2'  \n",
    "data = pd.DataFrame(data=np.array([x, y]).T, columns=[x_name, y_name])\n",
    "sns.jointplot(x=x_name, y=y_name, data=data, stat_func=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como veremos a continuación al usar PyMC3 no necesitamos marginalizar _manualmente_ los parámetros ya que el _a posteriori_ lo obtenemos como un _array_ que puede ser indexado para obtener la distribución marginal de cual parámetro de interés.\n",
    "\n",
    "Resumiendo cuando escuchemos que se habla sobre la distribución marginal de $x$,  simplemente se está diciendo que es la distribución de $x$ promediado sobre el resto de los parámetros.\n",
    "\n",
    "El marginalizar variables no solo sirve para obtener _rebanadas_ del _a posteriori_, puede ser una herramienta útil para simplificar el tratamiento matemático y/o computacional de un problema, veremos un ejemplo de esto en el capítulo 9 cuando hablemos sobre modelos de mezcla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Inferencias lumínicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 1882 Simon Newcomb realizó un experimento a fin de determinar la velocidad de la luz (en realidad realizó varios a lo largo de varios años). Newcomb midió el tiempo que le tomaba a la luz recorrer 7,4437 kilómetros. \n",
    "\n",
    "A continuación se muestra sus resultados, 66 mediciones expresadas en $1\\times10^{-2}$ segundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datos = np.array([24828, 24826, 24833, 24824, 24834, 24756, 24827, \n",
    "                  24816, 24840, 24798, 24829, 24822, 24824, 24821, \n",
    "                  24825, 24830, 24823, 24829, 24831, 24819, 24824, \n",
    "                  24820, 24836, 24832, 24836, 24828, 24825, 24821, \n",
    "                  24828, 24829, 24837, 24825, 24828, 24826, 24830, \n",
    "                  24832, 24836, 24826, 24830, 24822, 24836, 24823, \n",
    "                  24827, 24827, 24828, 24827, 24831, 24827, 24826, \n",
    "                  24833, 24826, 24832, 24832, 24824, 24839, 24828, \n",
    "                  24824, 24825, 24832, 24825, 24829, 24827, 24828, \n",
    "                  24829, 24816, 24823])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si graficamos estas medidas veremos que la distribución parece Gaussiana excepto por dos medidas inusualmente bajas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(datos);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por simplicidad vamos a suponer que los datos siguen una distribución Gaussiana, después de todo es lo que en general se esperaría al medir una misma _cosa_ varias veces. Una distribución Gaussiana queda definida por dos parámetros, la media y la desviación estándar, como desconocemos estas dos cantidades necesitamos establecer dos _a prioris_ uno para cada parámetro. Un modelo probabilístico razonable sería el siguiente.\n",
    "\n",
    "$$\\mu \\sim U(l, h)$$\n",
    "$$\\sigma \\sim \\text{Half-Normal}(\\sigma_{\\sigma})$$\n",
    "$$y \\sim \\mathcal{N}(\\mu, \\sigma)$$\n",
    "\n",
    "Es decir, $\\mu$ proviene de una distribución uniforme entre los límites $l$ y $h$ y $\\sigma$ proviene de una media-normal (_half-normal_) con desviación estándar $\\sigma_{\\sigma}$, esta distribución es como una Gaussiana pero restringida rango $[0, \\infty]$. Por último los datos $y$, como dijimos anteriormente, proviene de una distribución normal, especificada por $\\mu$ y $\\sigma$.\n",
    "\n",
    "Usando los diagramas de Kruschke:\n",
    "\n",
    "<img src=\"imagenes/velocidad_luz_g.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si desconocemos por completo cuales podrían ser los valores de $\\mu$ y de $\\sigma$, podemos fijar valores para los _a prioris_ que reflejen nuestra ignorancia. Para la distribución uniforme una opción podría ser fijar $(l=0, h=1\\times10^9)$, es decir asumimos que el tiempo que le demora a la luz recorrer los 7442 metros del experimento va entre 0 y 1 segundo (el límite inferior de 0 tiene sentido ya que las velocidades no pueden ser negativas, el límite superior de un 1 segundo es un valor elevado en la escala de los datos). Alternativamente podríamos haber elegido $(l=24000, h=25000)$, que es un rango bastante más amplio que el de los datos. Ante la duda calculen ambos modelos (y si lo desean otros posibles modelos) y evalúen el efecto que tiene uno y otro _a priori_. Para la distribución media-normal elegiremos $(\\sigma_\\sigma=10)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pm.Model() as modelo_g:\n",
    "    # los a prioris\n",
    "    mu = pm.Uniform('mu', 24000, 25000)\n",
    "    #mu = pm.Uniform('mu', 0, 1E10**9) # un a priori alternativo\n",
    "    sigma = pm.HalfNormal('sigma', sd=10)\n",
    "    # el likelihood\n",
    "    y = pm.Normal('y', mu=mu, sd=sigma, observed=datos)\n",
    "    trace_g = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El traceplot luce bien por lo que podemos continuar con el análisis pero ustedes podrían querer hacer algunas de las pruebas diagnósticas que vimos en el capítulo anterior (solo para estar seguros).\n",
    "\n",
    "Como se puede ver el traceplot tiene ahora dos filas, una por cada parámetro. Cada una de estas filas corresponde a una variable _marginal_ del _a posteriori_ que en este caso es bi-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm.traceplot(trace_g);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a llamar a `df_summary` y luego usaremos estos valores para compararlos con los de otro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm.df_summary(trace_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación podemos observar la distribución _a posteriori_ (que como ya mencionamos en bidimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(trace_g['mu'], trace_g['sigma']);\n",
    "plt.xlabel('mu')\n",
    "plt.ylabel('sigma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez computado el _a posteriori_ podemos realizar diversos cálculos a partir de el. Uno de esos cálculos consiste en _simular datos_ ($\\tilde{y}$). Matemáticamente lo que queremos calcular es:\n",
    "\n",
    "$$p(\\tilde{y} \\,|\\, y) = \\int p(\\tilde{y} \\,|\\, \\theta) \\, p(\\theta \\,|\\, y) \\, d\\theta$$\n",
    "\n",
    "donde:\n",
    "\n",
    "$y$ son los datos observados y $\\theta$ los parámetros del modelo. \n",
    "\n",
    "Siguiendo el ejemplo de la velocidad de la luz $\\theta$ corresponde a $\\mu$ y a $\\sigma$ y computacionalmente podemos obtener $\\tilde{y}$ de la siguiente forma:\n",
    "\n",
    "1. Elegimos al azar un índice del `trace` generado por PyMC3 (un valor para $\\mu_i$ y $\\sigma_i$)\n",
    "2. Generamos un _dato sintético_ $\\tilde{y}  \\sim N(\\mu_i, \\sigma_i$)$\n",
    "3. Repetimos 1 y 2 cuantas veces necesitemos.\n",
    "\n",
    "Usando PyMC3 es muy fácil generar datos a partir del _a posteriori_. El siguiente código devuelve 100 predicciones cada una de ellas de tamaño igual al de los datos (esto es importante para que la comparación sea _justa_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ppc = pm.sample_ppc(trace_g, 100, modelo_g, size=len(datos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos simulados los podemos usar para compararlos con los datos observados y de esta forma evaluar el modelo. Esto se conoce como prueba predictivas _a posteriori_ y ya adelantamos algo en el capítulo 1. En la siguiente gráfica la linea azul corresponde a los datos observados mientras que las lineas magentas (semitrasparentes) corresponden a datos predichos por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ỹ in ppc['y']:\n",
    "    sns.kdeplot(ỹ, color='m', alpha=0.1)\n",
    "sns.kdeplot(datos);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según la gráfica anterior, ¿Cuán bueno considerás que es nuestro modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Modelos robustos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un problema con el modelo anterior es que asume una distribución normal pero tenemos dos puntos que caen muy alejados de los valores medios. Esos puntos podrían estar alejados debido a errores experimentales en la toma de esos dos datos o podría haber un error al registrar los o al trascribirlos. Si algo de esto sucedió podríamos justificar su eliminación de nuestro conjunto de datos (dejando registro de la eliminación y de las razones por las cuales lo hicimos). Otra opción es usar el rango inter-cuartil (u otro método _estadístico_) para declarar esos dos puntos como datos aberrantes y desterrarlos de nuestros datos! Otra opción es dejarlos pero utilizar un modelo más robusto a valores alejados de la media. \n",
    "\n",
    "Uno de los inconvenientes al asumir normalidad, es que la media es muy sensible a valores aberrantes. La razón está en la colas de la Gaussiana, aún cuando las colas se extienden de $-\\infty$ a $\\infty$, la probabilidad de encontrar un valor cae rápidamente a medida que nos alejamos de la media, como se puede apreciar en la siguiente tabla que indica el porcentaje de valores que se encuentra a medida que nos alejamos de la media en unidades de desviación estándar (sd).\n",
    "\n",
    "| sd |  % |\n",
    "|:-:|:-:|\n",
    "| 1 |  68 |\n",
    "| 2 | 95  |\n",
    "| 3 | 99.7 |\n",
    "| 4 | 99.994 |\n",
    "| 5 | 99.99994 |\n",
    "\n",
    "Una alternativa a la distribución Gaussiana es usar una distribución t de Student, lo interesante de esta distribución es que además de estar definida por una media y una escala (análogo de la desviación estándar) está definida por un parámetro usualmente llamado $\\nu$. Por su uso en estadística frecuentista $\\nu$ se llama grados de libertad pero para el uso que se le suele dar en estadística Bayesiana tiene más sentido seguir la recomendación de Kruschke y llamarle parámetro de _normalidad_, ya que $\\nu$ controla cuan _gordas_ son las colas de la distribución. Cuando $nu=1$ (la distribución se llama de Cauchy o de Lorentz) las colas son muy gordas, el 95% de los puntos está entre -12,7 y 12,7, en cambio en una Gaussiana (con desviación estándar 1) esto ocurre entre -1,96 y 1,96. En el límite de $\\nu$ tendiendo a infinito estamos en presencia de una Gaussiana. La distribución t es realmente particular, cuando $nu <= 1$ la distribución no tiene media definida y la varianza solo está definida para valores de $nu > 2$.\n",
    "\n",
    "La siguiente figura muestra una distribución t de Student para distintos valores de $\\nu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "x_values = np.linspace(-10, 10, 200)\n",
    "for df in [1, 2, 5, 30]:\n",
    "    distri = stats.t(df)\n",
    "    x_pdf = distri.pdf(x_values)\n",
    "    plt.plot(x_values, x_pdf, label=r'$\\nu$ = {}'.format(df))\n",
    "\n",
    "x_pdf = stats.norm.pdf(x_values)\n",
    "plt.plot(x_values, x_pdf, label=r'$\\nu = \\infty$')\n",
    "plt.xlabel('$x$', fontsize=16)\n",
    "plt.ylabel('$pdf(x)$', rotation=90, fontsize=16)\n",
    "plt.legend(loc=0, fontsize=14)\n",
    "plt.xlim(-7, 7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que conocemos la distribución t de Student, podemos usarla en nuestro modelo:\n",
    "\n",
    "$$\\mu \\sim U(l, h)$$\n",
    "$$\\sigma \\sim \\mathcal{HN}(\\sigma_h)$$\n",
    "$$\\nu \\sim Expon(\\lambda)$$\n",
    "$$y \\sim \\mathcal{t}(\\mu, \\sigma, \\nu)$$\n",
    "\n",
    "En algunos modelos puede ser buena idea sumar 1 a la distribución exponencial a fin de asegurarse que $\\nu \\ge 1$ . En principio $\\nu$ puede tomar valores de [0, $\\infty]$, pero en mi experiencia valores de $\\nu < 1$ pueden traer problemas durante el muestreo, ya que pueden aparecer valores demasiado alejados de la media (las colas son extremadamente gordas!). Esto puede ocurrir con modelos con datos _marcadamente aberrantes_, veremos un ejemplo de esto en el capítulo 4.\n",
    "\n",
    "Gráficamente:\n",
    "\n",
    "<img src=\"imagenes/velocidad_luz_t.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pm.Model() as modelo_t:\n",
    "    # los a prioris\n",
    "    mu = pm.Uniform('mu', 24000, 25000)\n",
    "    sigma = pm.HalfNormal('sigma', sd=10)\n",
    "    nu = pm.Exponential('nu0', 1/30)\n",
    "    # el likelihood\n",
    "    y = pm.StudentT('y', mu=mu, sd=sigma, nu=nu, observed=datos)\n",
    "    trace_t = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm.traceplot(trace_t);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm.df_summary(trace_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, vemos que la estimación de $\\mu$ es muy similar entre los dos modelos, aunque la estimación de $\\sigma$, pasó de ser de ~10 a ~4. Esto es consecuencia de que la distribución t asigna menos peso a los valores alejados de la media que la distribución Gaussiana.\n",
    "\n",
    "Nota: Según mediciones más modernas $\\mu$ debería andar alrededor de ~22315, bastante alejado de las medidas realizadas por Newcomb en este experimento (otros experimentos realizados por el dieron valores más cercanos a las medidas actuales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sns.kdeplot(trace_t['mu'], trace_t['sigma']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos un prueba predictiva _a posteriori_ para el nuevo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ppc = pm.sample_ppc(trace_t, 100, modelo_t, size=len(datos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ỹ in ppc['y']:\n",
    "    sns.kdeplot(ỹ, color='r', alpha=0.1)\n",
    "sns.kdeplot(datos);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué conclusión se puede sacar de comparar esta ppc con la anterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Accidentes mineros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este ejemplo está tomado del [tutorial](http://pymc-devs.github.io/pymc3/getting_started/#case-study-2-coal-mining-disasters) de PyMC3. \n",
    "\n",
    "El problema es el siguiente tenemos un registro del número de accidentes en minas de carbón ubicadas en el Reino Unido que ocurrieron entre 1851 y 1962 ([Jarrett, 1979](http://biomet.oxfordjournals.org/content/66/1/191.abstract)). Se sospecha que la aplicación de ciertas regulaciones de seguridad tuvo como efecto una disminución en la cantidad de catástrofes. Por lo tanto nos interesa averiguar el año en que la tasa cambió y nos interesa estimar ambas tasas. \n",
    "\n",
    "Los datos son los siguientes, por un lado tenemos la variable _catástrofes_ que contiene la cantidad de accidentes por año y por el otro la variable _años_ conteniendo el rango de años para los cuales tenemos datos. Si prestan atención verán que _catástrofes_ es un arreglo enmascarado (o _masked array_). Esto es un tipo especial de arreglo de NumPy donde cada elemento del arreglo contiene asociado un valor _True_ o _False_ el cual indica si el elemento debe o no ser usado durante cualquier tipo de operación. En este caso como faltan datos para dos años lo que se ha hecho es marcar esa falta de datos con un valor centinela de -999, esta es la forma de indicarle a PyMC3 la presencia de datos faltantes, alternativamente se pueden pasar los datos como un _dataframe_ de Pandas conteniendo el valor especial `NAN` (que es el valor por defecto en Pandas para lidiar con datos faltantes).\n",
    "\n",
    "Bien, pero para que molestarse con datos faltantes si en general es más fácil eliminarlos. una de las razones es que esto puede conducir a pérdida de información cuando por cada observación tenemos más de una variable o cantidad de interés. Por ejemplo si tenemos 50 sujetos a los que les hemos medido la presión, la temperatura y el ritmo cardíaco, pero sucede que para 4 de ellos no contamos con el datos de la presión (por que alguien se olvidó de medirlo o registrarlo, o por que el tensiómetro se rompió, o por lo que sea). Podemos eliminar esos cuatro sujetos del análisis y perder por lo tanto información sobre la presión y ritmo cardíaco, o podemos usar todos los datos disponibles y además estimar los valores de temperatura faltantes. En el contexto de la estadística Bayesiana los datos faltantes se tratan como un parámetro desconocido del modelo que puede ser estimado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catástrofes = np.ma.masked_values([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,\n",
    "                            3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,\n",
    "                            2, 2, 3, 4, 2, 1, 3, -999, 2, 1, 1, 1, 1, 3, 0, 0,\n",
    "                            1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,\n",
    "                            0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,\n",
    "                            3, 3, 1, -999, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,\n",
    "                            0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1], value=-999)\n",
    "años = np.arange(1851, 1962)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(años, catástrofes, 'o')\n",
    "plt.ylabel(\"Número de accidentes\")\n",
    "plt.xlabel(\"Año\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para modelar los accidentes usaremos una distribución de Poisson. Como creemos que la cantidad media de accidentes es distinta antes y después de la introducción de regulaciones de seguridad usaremos dos valores de tasas medias de accidentes ($t_0$ y $t_1$). Además deberemos estimar un punto de corte ($pc$) que dividirá los años para los cuales se aplica la tasa de accidentes $t_0$ de los cuales se aplica la tasa $t_1$:\n",
    "\n",
    "$$A_t \\sim Poisson(tasa)$$\n",
    "\n",
    "$$tasa = \\begin{cases}\n",
    "t_0, \\text{si } t \\ge pc,\\\\\n",
    "t_1, \\text{si } t \\lt pc\n",
    "\\end{cases}$$\n",
    "\n",
    "Los _a prioris_ que usaremos serán:\n",
    "\n",
    "$$t_0 \\sim Expon(1)$$\n",
    "$$t_1 \\sim Expon(1)$$\n",
    "$$pc \\sim U(A_0, A_1)$$\n",
    "\n",
    "Donde la distribucion uniforme es discreta y $A_0$ y $A_1$ corresponden al primer y último año considerado en el análisis respectivamente \n",
    "\n",
    "\n",
    "Gráficamente el modelo es:\n",
    "\n",
    "\n",
    "\n",
    "Una peculiaridad de la implementación de este modelo en PyMC3 es el uso de la función _pm.switch_ (linea 10). Esta es en realidad una función de Theano y equivale a un _if else_ de Python. Si el primer argumento es _True_ entonces devuelve el segundo argumento caso contrario el tercer argumento. Como resultado tenemos que _tasa_ es un vector de longitud igual a la de _años_ y cuyos elementos corresponden a una repetición $t_0$ seguida de una repetición $t_1$, la cantidad exacta de repeticiones de $t_0$ y $t_1$ está controlada por la condición $pc \\ge$ _años_. De esta podemos al muestrear $pc$ modificamos que años reciben cual tasa para el cálculo del _likelihood_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tasa = []\n",
    "# for año in años:\n",
    "#     if pc >= años:\n",
    "#         tasa.append(t_0)\n",
    "#     else:\n",
    "#         tasa.append(t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pm.Model() as modelo_cat:\n",
    "\n",
    "    pc = pm.DiscreteUniform('pc', lower=años.min(), upper=años.max(), testval=1900)\n",
    "\n",
    "    # Priors para las tasas antes y después del cambio.\n",
    "    t_0 = pm.Exponential('t_0', 1)\n",
    "    t_1 = pm.Exponential('t_1', 1)\n",
    "\n",
    "    # Asignamos las tasas a los años de acuerdo a pc\n",
    "    tasa = pm.math.switch(pc >= años, t_0, t_1)\n",
    "\n",
    "    disasters = pm.Poisson('disasters', tasa, observed=catástrofes)\n",
    "    trace_cat = pm.sample(4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cadena_cat = trace_cat[500::]\n",
    "pm.traceplot(cadena_cat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm.df_summary(cadena_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(años, catástrofes, 'o')\n",
    "plt.ylabel(\"Número de accidentes\")\n",
    "plt.xlabel(\"Año\")\n",
    "\n",
    "plt.axvline(cadena_cat['pc'].mean(), color='red')\n",
    "pc_hpd = pm.hpd(cadena_cat['pc'])\n",
    "plt.fill_betweenx(y=[catástrofes.min(), catástrofes.max()], x1=pc_hpd[0], x2=pc_hpd[1], alpha=0.5, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Modelos Jerárquicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente ejemplo está tomado del capítulo 9 del libro \"Doing Bayesian Data Analysis de John K. Kruschke\". Supongamos que en vez de 1 moneda tenemos 3, supongamos además que sabemos que las tres monedas fueron echas con la misma matriz (en la misma fábrica). Para estimar el valor de $\\theta$ tenemos dos opciones:\n",
    "\n",
    "1) estimar un valor de $\\theta$ para cada moneda por separado.\n",
    "\n",
    "2) juntar las tres monedas en un mismo conjunto de datos y calcular un solo valor de $\\theta$\n",
    "\n",
    "La ventaja de la opción 1 es que las monedas podrían diferir entre si por lo que calcular 3 valores de  $\\theta$ podría ser muy informativo. La desventaja de este modelo es que hace caso omiso a la información que indica que las 3 monedas tienen un origen común, por lo que es probable que compartan características.\n",
    "\n",
    "La ventaja de la opción 2 es que la cantidad de datos por parámetro aumentó, lo que reduce la incerteza. El problema es que pasamos a asumir que las 3 monedas son en realidad una, lo cual no sería problemático si las tres monedas fueran muy similares entre si, pero esto podría no ser una buena aproximación.\n",
    "\n",
    "Una tercera opción es hacer algo a mitad de camino entre 1 y 2. Esto se consigue construyendo un modelo jerárquico o modelo multinivel. Este tipo de modelo nos permitirá estimar un valor de $\\theta$ para cada moneda de forma tal que la estimación de cada valor de $\\theta$ influencie al resto.\n",
    "\n",
    "En estadística Bayesiana construir modelos jerárquicos es sencillo. A continuación veremos que un modelo jerárquico para las 3 monedas es muy similar al usado para el caso de 1 sola moneda solo que ahora colocamos un _a priori_ sobre el _a priori_!\n",
    "\n",
    "Recordemos, el modelo del capítulo anterior era:\n",
    "\n",
    "$$\\theta \\sim \\operatorname{Beta}(\\alpha, \\beta)$$\n",
    "$$y \\sim \\operatorname{Bin}(n=1, p=\\theta)$$\n",
    "\n",
    "En un modelo jerárquico los argumentos de la distribución Beta ($\\alpha$ y $\\beta$) no son constantes si no que son valores que proviene de alguna otra distribución. En nuestro tendremos que:\n",
    "\n",
    "$$ \\mu \\sim \\operatorname{Beta}(\\alpha, \\beta)$$\n",
    "$$ \\kappa = \\operatorname{Gamma}(s, r)$$\n",
    "\n",
    "$$\\theta \\sim \\operatorname{Beta}(\\alpha=\\mu  \\kappa, \\beta=(1 - \\mu)  \\kappa)$$\n",
    "$$y \\sim \\operatorname{Bin}(n=1, p=\\theta)$$\n",
    "\n",
    "Gráficamente, tenemos:\n",
    "\n",
    "<img src=\"imagenes/modelo_3_monedas_jerarquico.png\" width=250>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los modelos jerárquicos a $\\mu$ y a $\\kappa$ se llama _hiper a prioris_ o _hiperparámetros_ ya que son ellos quienes determinan el valor del _a priori_. La diferencia entre el modelo del capítulo anterior y el del presente es que ahora los valores que puede tomar $\\theta$ dependen no ya de una distribución fija($\\alpha=1$ y $\\beta=1$) si no de una distribución que depende de los valores de $\\mu$ y $\\kappa$, y que estimaremos a partir de los datos. Es decir es posible estimar el _a priori_ a partir de los datos, pero solo por que hemos introducido _hiper a prioris_. \n",
    "\n",
    "Recordarán que la distribución Beta se podía parametrizar en términos de $\\alpha$ y $\\beta$, pero también de $\\mu$  y $\\kappa$, donde $\\mu$ es la media y $\\kappa$ es la concentración (la inversa de la dispersión). Tenemos entonces que $\\mu$ reflejará el valor promedio de 3 valores de $\\theta$ y que si la proporción de caras en las tres monedas es similar entre si $\\kappa$ tomara un valor más alto, mientras que si las monedas son diferentes entre si $\\kappa$ tomará un valor más bajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 ¿Por qué la elección de los hiper _a prioris_?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bueno dado que $\\mu$ es la media del vector $\\theta$ (y que $\\theta$ solo puede tomar valores entre 0 y 1), $\\mu$ queda restringida a valores entre 0 y 1 (al igual que una distribución beta), siguiendo el mismo razonamiento $\\kappa$ va entre $[0, \\infty]$ al igual que la distribución gamma. Otras distribuciones igualmente razonables podrían haber sido:\n",
    "\n",
    "* $ \\mu \\sim U(0, 1)$\n",
    "* $ \\kappa \\sim \\mathcal{HN}(\\sigma=100)$\n",
    "\n",
    "\n",
    "Primero que nada generemos algunos datos sintéticos y los pondremos de una forma que sea más simple pasárselos al modelo, esto quedará un poco más claro al la especificación del modelo.\n",
    "\n",
    "Vamos a suponer que con cada una de las 3 monedas hicimos 10 experimentos de Bernoulli (las arrojamos al aire) y obtuvimos como resultado, para cada caso, 5 caras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N =  [10, 10, 10]  # Número de experimentos por moneda\n",
    "z =  [5, 5, 5]  # Número de caras en los Ni experimentos.\n",
    "\n",
    "# vector conteniendo los índices para cada moneda (desde 0 al número de monedas)\n",
    "monedas = np.repeat(np.arange(len(N)), N)\n",
    "# lista con 1 para caras y 0 para cecas\n",
    "datos = []  \n",
    "for i, experimentos in enumerate(N):\n",
    "    datos.extend(np.repeat([1, 0], [z[i], N[i]-z[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no sabemos demasiado sobre $\\mu$ y $\\kappa$, vamos a elegir $ \\mu \\sim \\operatorname{Beta}(\\alpha=2, \\beta=2)$, lo que equivale a una distribución centrada en 0.5, pero que casi asigna la misma probabilidad a todos los valores entre 0 y 1. Y $ \\kappa = \\operatorname{Gamma}(s=1, r=0.1)$, lo que equivale a una curva con media y  desviación estándar 10.\n",
    "\n",
    "La especificación del modelo es igual a lo que hemos venido haciendo la única diferencia es que en la linea 7 podemos observar que hay una argumento llamando _shape_. Esto nos permite especificar las dimensiones de (en este caso) _theta_. PyMC3 permite escribir modelos _vectorizados_ ahorrándonos el tener que escribir _for loops_. Esa es la razón por la cual en la celda superior creamos un vector _monedas_ que usamos en la linea 9 (de la especificación del modelo) para indexar _theta_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pm.Model() as modelo_j:\n",
    "    # definimos los hiperparámetros\n",
    "    mu = pm.Beta('mu', alpha=2, beta=2)\n",
    "    kappa = pm.Gamma('kappa', alpha=1, beta=0.1)\n",
    "    #kappa = pm.Gamma('kappa', mu=10, sd=10)\n",
    "    \n",
    "    # definimos el a priori\n",
    "    theta = pm.Beta('theta', mu * kappa, (1 - mu) * kappa, shape=len(N))\n",
    "    # definimos el likelihood\n",
    "    y = pm.Bernoulli('y', p=theta[monedas], observed=datos)\n",
    "\n",
    "    # muestreamos\n",
    "    trace_j = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm.traceplot(trace_j);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pm.autocorrplot(trace_j);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm.df_summary(trace_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que el valor de $\\kappa$ del _a posteriori_ es mayor que del _a priori_. Esto es razonable ya que los experimentos con las 3 han resultado idénticos indicando que la matriz tiene un efecto importante sobre el resultado de $\\theta$ para cada moneda.\n",
    "\n",
    "¿Qué distribución hubiéramos obtenido para $\\kappa$ si las monedan hubieran mostrado distintos resultados?\n",
    "Probemos que hubiera pasado si:\n",
    "\n",
    "z = [1, 5, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Mirando el _a posteriori_ desde varios lados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El _a posteriori_ contiene toda la información que resulta de un análisis Bayesiano. Por lo que puede ser muy informativo analizarlo desde varios lados. Además de los gráficos que provee PyMC3, podemos analizar el _a posteriori_ usando nuestras propias gráficas, por ejemplo podemos estar interesados en observar como se correlacionan distintos parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creamos arreglos tomando muestras del posterior\n",
    "theta1_pos = trace_j['theta'][:,0]\n",
    "theta2_pos = trace_j['theta'][:,1]\n",
    "theta3_pos = trace_j['theta'][:,2]\n",
    "mu_pos = trace_j['mu']\n",
    "kappa_pos = trace_j['kappa']\n",
    "\n",
    "_, ax = plt.subplots(4, 3, figsize=(12, 12))\n",
    "\n",
    "# Gráficos de dispersión de los hiper-parámetros\n",
    "ax[0, 0].scatter(mu_pos, kappa_pos, marker='o', alpha=0.01)\n",
    "ax[0, 0].set_xlim(0,1)\n",
    "ax[0, 0].set_xlabel(r'$\\mu$')\n",
    "ax[0, 0].set_ylabel(r'$\\kappa$')\n",
    "\n",
    "pm.plot_posterior(mu_pos, ax=ax[0, 1], kde_plot=True, round_to=1)\n",
    "ax[0, 1].set_xlabel(r'$\\mu$')\n",
    "ax[0, 1].set_xlim(0,1)\n",
    "\n",
    "pm.plot_posterior(kappa_pos, ax=ax[0, 2], kde_plot=True, round_to=1)\n",
    "ax[0, 2].set_xlabel(r'$\\kappa$')\n",
    "count = 1\n",
    "for i, j in (theta1_pos, 'theta1'), (theta2_pos, 'theta2'), (theta3_pos, 'theta3'):\n",
    "    pm.plot_posterior(i, ax=ax[count, 0], kde_plot=True, round_to=1)\n",
    "    ax[count, 0].set_xlabel('$\\{}$'.format(j))\n",
    "    ax[count, 0].set_xlim(0,1)\n",
    "    countb = 1\n",
    "    for k, l in (mu_pos, 'mu'), (kappa_pos, 'kappa'):\n",
    "        ax[count, countb].scatter(k, i, marker='o', alpha=0.1)\n",
    "        ax[count, countb].set_xlabel('$\\{}$'.format(l))\n",
    "        ax[count, countb].set_ylabel('$\\{}$'.format(j), rotation=0)\n",
    "        ax[count, countb].set_xlim(0)\n",
    "        ax[count, countb].set_ylim(0,1)\n",
    "        countb += 1\n",
    "    count += 1\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Contracción (_shrinking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos ahora con otros ejemplos (puede ser conveniente guardar las figuras obtenidas con distintos nombres).\n",
    "\n",
    "* z = [1,1,1] \n",
    "* z = [9,9,9] \n",
    "* z = [9,1,9]\n",
    "\n",
    "¿Cuáles son los valores de $\\theta$ obtenidos en cada caso? Es lo mismo el valor estimado de $\\theta$ para una moneda cuando cae 1 de 10 veces caras (y las otras dos también), que cuando una moneda cae 1 de 10 veces caras y las otras dos caen 9 de 10 veces cara?\n",
    "\n",
    "Como podrán ver si hacen el ejercicio, el valor estimado $\\theta$ no es el mismo! ¿Por qué sucede esto?\n",
    "\n",
    "Porque el modelo especifica que las monedas NO son independientes. El modelo asume que las 3 monedas provienen de una misma matriz, por lo tanto la estimación de $\\theta$ para una moneda es afectada por las otras y al mismo tiempo afecta a las otras. Este fenómeno se llama contracción, la razón del nombre es que las estimaciones individuales tienden a contraerse alrededor del valor promedio de las 3 estimaciones (en nuestro modelo $\\mu$) esto se hace mas evidente para los valores _aberrantes_. Si todas las monedas menos una indican un valor de $\\theta$ más o menos similar la que posee el valor distinto tendrá un $\\theta$ mucho más cercano al valor de las demás que si la hubiéramos estimado de forma individual.\n",
    "\n",
    "Esto quizá pueda parecerles problemático, pero no es más que un reflejo de lo que asumimos al crear el modelo. La matriz con la que fueron echas las monedas influencia el sesgo de las mismas. Entonces, la estimación de cada elemento del vector $\\theta$ debe influenciar y ser influenciado por las estimaciones de los demás elementos de $\\theta$. Esto es una forma de regularización que los métodos frecuentistas deben introducir _ad-hoc_, pero que sin embargo ya viene incluido en un análisis Bayesiano.\n",
    "\n",
    "Entonces el modelo jerárquico Bayesiano que hemos construido nos dice no solo los valores de $\\theta$, si no lo valores de $\\mu$ (el sesgo promedio) introducido por la matriz y los valores de $\\kappa$, cuan fuerte es el efecto de la matriz sobre los sesgos individuales de $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Para seguir leyendo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Más sobre modelos jerárquicos en:\n",
    "    * Capítulo 9 de [Doing Bayesian Data Analysis (2 edición)](www.amazon.com/gp/product/0124058884) de John Kruschke.\n",
    "    * Capítulo 12 de [Statistical Rethinking](https://www.crcpress.com/Statistical-Rethinking-A-Bayesian-Course-with-Examples-in-R-and-Stan/McElreath/9781482253443) de Richard McElreath.\n",
    "\n",
    "* Material online con tópicos Bayesianos:\n",
    "    * [Publishable Stuff](http://sumsar.net/)\n",
    "    * [Probably Overthinking It](http://allendowney.blogspot.com.ar/)\n",
    "    * [Pythonic Perambulations](http://jakevdp.github.io./)\n",
    "    * [While My MCMC Gently Samples](http://twiecki.github.io/)\n",
    "    * [Count Bayesie](https://www.countbayesie.com/)\n",
    "    * [Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/#contents)   \n",
    "\n",
    "\n",
    "* Las plantillas utilizadas para generar los diagramas de Kruschke, fueron creadas por [Rasmus Bååth's](http://sumsar.net/blog/2013/10/diy-kruschke-style-diagrams/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, IPython, scipy, matplotlib, platform\n",
    "print(\"Esta notebook fue creada en una computadora %s corriendo %s y usando:\\nPython %s\\nIPython %s\\nPyMC3 %s\\nNumPy %s\\nSciPy %s\\nMatplotlib %s\\nSeaborn %s\\n\" % (platform.machine(), ' '.join(platform.linux_distribution()[:2]), sys.version[:5], IPython.__version__, pm.__version__, np.__version__, scipy.__version__, matplotlib.__version__, sns.__version__))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
