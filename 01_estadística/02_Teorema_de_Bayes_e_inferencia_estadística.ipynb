{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Índice\n",
    "* [1. Teorema de Bayes e inferencia estadística](#1.-Teorema-de-Bayes-e-inferencia-estadística)\n",
    "\t* [1.1 Estadística Frecuentista vs Bayesiana](#1.1-Estadística-Frecuentista-vs-Bayesiana)\n",
    "\t\t* [1.1.1 El mundo según Bayes](#1.1.1-El-mundo-según-Bayes)\n",
    "\t* [1.2 Interpretación Bayesiana (_subjetiva_) de la probabilidad](#1.2-Interpretación-Bayesiana-%28_subjetiva_%29-de-la-probabilidad)\n",
    "\t* [1.3 El teorema de Bayes](#1.3-El-teorema-de-Bayes)\n",
    "\t* [1.4 Estadística Bayesiana en tres pasos.](#1.4-Estadística-Bayesiana-en-tres-pasos.)\n",
    "\t* [1.5 Estimación de parámetros](#1.5-Estimación-de-parámetros)\n",
    "\t\t* [1.5.1 el problema del diagnóstico](#1.5.1-el-problema-del-diagnóstico)\n",
    "\t\t* [1.5.2 El problema de la moneda](#1.5.2-El-problema-de-la-moneda)\n",
    "\t* [1.6 Elección del  _a priori_](#1.6-Elección-del--_a-priori_)\n",
    "\t* [1.7 Interpretación del  _posteriori_](#1.7-Interpretación-del--_posteriori_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Teorema de Bayes e inferencia estadística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este curso aprenderemos sobre otro paradigma en estadística llamado usualmente estadística Bayesiana. El se debe a Thomas Bayes (1702-1761) un ministro presbiteriano y mathematico aficionado quien derivo por primera vez el teorema de Bayes, el cual fue publicado (postumanente) en 1763. Sin embargo una de las primera personas en realmente desarrollar métodos (ahora llamados) Bayesianos, fue Pierre-Simon Laplace (1749-1827), por lo que muchos argumentan que deberíamos hablar de estadística Laplaciana en vez de Bayesiana.\n",
    "\n",
    "Existe otro paradigma estadístico llamado estadística clásica o frecuentista. Es probable que ustedes hayan tenido al menos un curso de estadística (ya sea en el grado o posgrado) y que casi con seguridad dicho curso haya sido sobre métodos frecuentistas (aun cuando esto no haya sido explicitado).Es interesante notar que estos métodos \"clásicos\" fueron desarrollados principalmente durante el siglo XX y que la estadística Bayesiana, que parece ser la moda o lo \"novedoso\" tenga sus origenes en el siglo XVII.\n",
    "\n",
    "A lo largo del curso contrastaremos algunas de las diferencias y similitudes entre ambas aproximaciones a la estadística. Mucho se ha escrito sobre las ventajas y desventajas de cada aproximación. Es claro que quien escribe cree que son más las ventajas de la estadística Bayesiana que sus desventajas, sin embargo he decidio tomar una postura más pragmática por lo que no entraremos en la discusion filosófico/matematica sobre el tema, si no que nos focalizaremos en discutir como hacer estadística Bayesiana. De todas formas dado que la discusión no me parece esteril más adelante encontraran varias referencias a estas discusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Estadística Frecuentista vs Bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo cualquier paradigma estadístico encontraremos los siguientes elementos:\n",
    "\n",
    "1. Algunas cantidades que son desconocidas, pero queremos conocer. Estas cantidades son llamadas **parámetros**\n",
    "2. Algunas cantidades observadas y que sospechamos contienen información sobre los parámetros: Estas cantidades son llamadas **datos** \n",
    "3. Una (o más) construcciones matemáticas que relacionan los datos con los parámetros. Estos son los llamados **modelos**.\n",
    "\n",
    "En un paradigma frecuentista los datos son considerados aleatorios. La razón es que cada vez que realizamos un experimento u observación obtenemos valores diferentes para los datos. Por el contrario se considera que existen valores verdaderos para los parámetros y que estos valores son fijos, es por ello que en estadística frecuentista las estimaciones se condicionan sobre los parámetros, es decir el modelo general en estadística frecuentista es:\n",
    "\n",
    "$$f(y | \\theta)\\\\$$\n",
    "\n",
    "\n",
    "Donde el modelo $f$ acepta como argumentos los datos $y$ condicionados (el simbolo $|$ es usado para indicar una probabilidad condicional) en valores particulares de $\\theta$.\n",
    "\n",
    "La inferencia frecuentista típicamente involucra es uso de **estimadores** para los parámetros desconocidos. Los estimadores son fórmulas que devuelven estimaciones como función de los datos. Los estimadores se eligen de acuerdo a diversos criterios de optimalidad. Como pueden ser  insesgadez, eficiencia, convergencia y robustez (consistencia).\n",
    "\n",
    "Supongamos que hemos recolectado datos sobre la prevalencia de alguna enfermedad en una población dada. Hemos recolectado datos de $n$ pacientes de los cuales $y$ han sido diagnosticados con la enfermedad. Un estimador frecuentista de la prevalencia $p$ de dicha enfermedad será:\n",
    "\n",
    "$$p = \\frac{y}{n}$$\n",
    "\n",
    "¿Por qué esta función en particular? Si bien la respuesta es tan intuitiva que parece *obvia* es posible justificar (matemáticamente) el uso de ese estimador ya que puede demostrarse que este estimador provee de una estimación no-sesgada (no sobre estima ni subestima a $p$) y con mínima varianza (la dispersión respecto del valor real de $p$ es mínima).\n",
    "\n",
    "En el universo frecuentista cada vez que se quiere estimar una cantidad es necesario introducir nuevos estimadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 El mundo según Bayes\n",
    "\n",
    "En el universo Bayesiano los datos son considerados fijos. En el sentido que aún si los concebimos como variables aleatorias una vez que los datos son recolectados estos ya no cambian. Los parámetros de nuestro modelo son considerados aleatorios, no por que necesariamente lo sean si no por que desconocemos los valores que pueden tomar y el grado de incertidumbre sobre los valores que pueden tomar se modela usando probabilidades. Por lo tanto en estadística Bayesiana lo que nos suele interesar determinar es:\n",
    "\n",
    "$$p(\\theta | y)$$\n",
    "\n",
    "Es decir la probabilidad de que $\\theta$ tome ciertos valores dado (o condicionado en) los valores observados de $y$. En algún momento de la historia la estadistica Bayesiana recibió el nombre de **probabilidad inversa**, ya que infiere a partir de las observaciones los parámetros, lo que se suele interpretar como inferir las causas a partir de los efectos.\n",
    "\n",
    "En estadística Bayesiana existe un solo estimador para todos los posibles problemas que se nos presenten. Este estimador se conoce como teorema de Bayes (o regla de Bayes o formula de Bayes). Antes de presentar este único estimador, repasemos rápidamentes algunos conceptos sobre probabiliad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Interpretación Bayesiana (_subjetiva_) de la probabilidad\n",
    "\n",
    "Las probabiliades son números entre 0 y 1 (incluyendo ambos extremos). En estadística Bayesiana las probabilidades son usadas para cuantificar la confianza que tenemos en que un evento ocurra. Desde este punto de vista es totalmente razonable preguntar cual es la probabilidad de que la masa de Saturno sea $5 \\times 10^{26}$ kg, o hablar sobre la probabilidad de lluvia durante el 25 de Mayo de 1810, o la probabilidad de que mañana amanezca.\n",
    "\n",
    "La lógica aristotélica permite razonar de forma correcta cuando los enunciados son verdaderos o falsos (cuando hay certezas). A fin de razonar, de forma correcta, en presencia de incertidumbre  es necesario extender la lógica aristotélica. En 1946, Richard Cox demostró que tal extensión es posible si asignamos probabilidades a los enunciados y si las probabilidades usadas respetan las conocidas reglas de la teoría de probabilidades:\n",
    "\n",
    "La regla de la suma:\n",
    "$$p(A) + p (\\neg A) = 1$$ \n",
    "\n",
    "La regla del producto:\n",
    "$$p(A, B) = p(A|B) \\times p(B)$$ \n",
    "\n",
    "Siendo p(falso)= 0 y p(verdadero) = 1\n",
    "\n",
    "Si no estamos seguros de la factibilidad de un evento, entonces es matemáticamente razonable asignar un valor entre 0 y 1, de acuerdo al grado de confianza que tenemos de que ocurra dicho evento. \n",
    "\n",
    "Dado que las probabilidades son una medida de la incerteza y no una propiedad de la naturaleza, distintas personas podrán asignar distintas probabilidades a un mismo evento. Por ello se suele decir que la estadística Bayesiana es subjetiva (y no como un cumplido!). Sin embargo, este uso de las probabilidades simplemente refleja un hecho trivial, distintas personas poseen diferente información por lo que no necesariamente estarán de acuerdo en la factibilidad de un evento. Una persona que sabe que una moneda está sesgada hacia cara, maneja información distinta de otra que asume que una moneda tiene igual chance de caer cara o seca. De todas formas, si ambas personas hacen el experimento de arrojar esa moneda al aire varias veces, la probabilidad que cada uno asigna al _evento cara_ irá convergiendo a un mismo valor (aun si nunca coincide exactamente). Más adelante realizaremos tal experimento de forma computacional. Pero antes veamos el teorema de Bayes, que describe la forma matemáticamente correcta de actualizar nuestras creencias a la luz de nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 El teorema de Bayes\n",
    "\n",
    "Según la regla del producto tenemos que la probabiliad de que ocurra un evento A y uno B, si ambos son independientes, es igual al producto de sus probabilidades.\n",
    "\n",
    "$$p(A, B) = p(A) \\times p(B)$$ \n",
    "\n",
    "Pero ¿Qué pasa en cuando los eventos no son independientes? En es caso podes decir que:\n",
    "\n",
    "$$p(A, B) = p(A|B) \\times p(B)$$ \n",
    "\n",
    "$p(A|B)$ es lo que se conoce como probabilidad condicional y se lee _la probabilidad de $A$ dado $B$_. Y representa la probabilidad de que ocurra $A$ dado que sabemos $B$ (o _condicionado_ a que sabemos $B$). Ya estamos muy cerca del teorema de Bayes, pero detengamonos un segundo a contemplar el significado de una probabilidad condicional. Reordenando la ecuación anterior se ve que:\n",
    "\n",
    "$$p(A|B) = \\frac{p(A, B)}{p(B)}$$ \n",
    "\n",
    "Es decir $p(A|B)$ es la probabilidad de que ocurra $A$ y $B$ de forma conjunta ($p(A, B)$), pero relativo a la probabilidad de que ocurra $p(B)$. ¿Por qué dividimos por $p(B)$? Debido a que conocer $B$ equivale a decir que el espacio total de posibilidades se ha reducido a $B$, es decir es necesario normalizar. ¿Cuál es la probabilidad de arrojar un dado y obtener 1? $\\frac{1}{6}$ (asumiendo un dado no trucado) y ¿Cuál es la probabilidad de arrojar un dado y obtener 1 dado que he obtenido un número impar? $\\frac{1}{3}$ (asumiendo nuevamente un dado no trucado). De hecho es posible asegurar que:\n",
    "\n",
    "$$P(A|B) >= P(A)$$\n",
    "\n",
    "Si $B$ aporta información sobre $A$ (obtuve un número impar), entonces $P(A|B) > P(A)$. Si el saber $B$ no aporta ninguna informacion sobre $A$ (las rosas son rojas), entonces $P(A|B) = P(A)$. En este último caso tendremos que ambas variables son independientes entre si y podemos escribir nuevamente.\n",
    "\n",
    "$$p(A, B) = p(A) \\times p(B)$$\n",
    "\n",
    "\n",
    "Luego de este pequeño desvío por la probabilidad condicional sigamos nuestro camino.\n",
    "\n",
    "El teorema de Bayes es una consecuencia directa de la regla del producto, veamos.\n",
    "\n",
    "$$p(H,D) = p(H|D) \\times p(D)$$\n",
    "$$p(D,H) = p(D|H) \\times p(H)$$\n",
    "\n",
    "y dado que:\n",
    "\n",
    "$$p(H,D) = p(D,H)$$\n",
    "\n",
    "Podemos escribir que:\n",
    "\n",
    "$$p(H|D) \\times p(D) = p(D|H) \\times p(H)$$\n",
    "\n",
    "Reordenando llegamos al teorema de Bayes.\n",
    "\n",
    "$$p(H|D) = \\frac{p(D|H) p(H)}{p(D)}$$\n",
    "\n",
    "El cual también suele ser escrito de la siguiente forma:\n",
    "\n",
    "$$p(H|D) = \\frac{p(D|H)p(H)}{\\sum_{H^*} p(D|H^*)p(H^*)}$$\n",
    "\n",
    "En esta segunda forma el valor de $H$ en el numerador hace referencia a un valor particular, mientras que en el denominador $H^*$ hace referencia a todos los valores posibles de $H$. La sumatoria es reemplazada por una integral en el caso que estemos hablando de valores continuos y no discretos.\n",
    "\n",
    "Esta ecuación (de aspecto, casi trivial) es invaluable por que nos permite relacionar la probabilidad $p(H|D)$ con $p(D|H)$. Si reemplazamos $H$ por _hipótesis_ y $D$ por _datos_ creo que empieza a generarse cierta intuición acerca de la importancia del teorema de Bayes en ciencia.\n",
    "\n",
    "Cada término del teorema de Bayes tiene un nombre específico:\n",
    "\n",
    "* $p(H|D)$: _a posteriori_ \n",
    "* $p(D|H)$: _likelihood_ (_verosimilitud_)\n",
    "* $p(H)$: _a priori_\n",
    "* $p(D)$: _evidencia_\n",
    "\n",
    "El _a priori_ representa nuestro conocimiento (o ignorancia!) sobre la plausibilidad de nuestra hipótesis antes de analizar los datos. Esta es la parte que le da la _subjetividad_ a la estadística Bayesiana. En muchos problemas científicos (y de otra índole) es posible contar con mucha información _objetiva_ que puede usarse como _a priori_, como medidas experimentales previas o límites impuesto por alguna teoría. \n",
    "\n",
    "El _likelihood_ es la forma de incluir nuestros datos en el análisis.\n",
    "\n",
    "El _a posteriori_ representa la plausibilidad de nuestra hipótesis a la luz de los datos (y del _a priori_). Puede pensarse como una versión actualizada del _a priori_. \n",
    "\n",
    "La _evidencia_ es la probabilidad de observar los datos $D$ dado todas las posibles hipótesis $H$. Si la oración anterior no es muy clara, no hay problema ya veremos ejemplos que clarificarán este concepto. En general, la _evidencia_ puede ser vista como una simple constante de normalización que en muchos problemas prácticos puede (y suele) omitirse sin perdida de generalidad. Por lo que el teorema de Bayes suele aparecer escrito como\n",
    "\n",
    "$$p(H|D) \\propto p(D|H) p(H)$$\n",
    "\n",
    "\n",
    "El rol de todos estos términos irá quedando más claro a medida que avancemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Estadística Bayesiana en tres pasos.\n",
    "\n",
    "El teorema de Bayes es el único estimador usado en estadística Bayesiana. Lo que hace, al menos en principio, sea conceptualmente simple de usar. Según Gelman et al. (2013) la estadística Bayesiana se reduce a tres pasos:\n",
    "\n",
    "1. Generar un modelo probabilístico usando el teorema de Bayes. Esto incluye asignar distribuciones de probabilidad a los datos, parámetros desconocidos, datos faltantes, etc.\n",
    "2. Condicionar el modelo a los datos observados a fin de obtener el _a posteriori_. En general, salvo algunas casos simples, esto debe resolverse por métodos numéricos.\n",
    "3. Evaluar el ajuste del modelo generado a los datos y evaluar las implicancias del modelo. Este paso no es exclusivo de la estadística Bayesiana si no que es generar de cualquier ejercicio de modelado de un problema. En general uno debe evaluar si el modelo ajusta efectivamente a los datos generados, si las conclusiones obtenidas tienen sentido dado el marco conceptual en el que uno trabaja, cuan sensibles son los resultados a las detalles del modelo (sobre todo a detalles para los cuales no tenemos demasiada información). Es decir en necesario validar el modelo mediante una evaluación lo más crítica (y honesta) posible de los propios resultados.\n",
    "\n",
    "Durante el resto del curso iremos discutiendo y recorriendo cada uno de estos pasos. El primer paso es quizá el más complicado de todos, en lo que resta de este capítulo veremos como obtener el _a posteriori_ de forma analítica, pero a partir del próximo capítulo lo haremos de forma computacional gracias a librería de Python llamada PyMC3. A medida que crezca la complejidad de nuestros modelos veremos como el último punto toma cada vez mayor importancia y veremos que, hasta cierto punto, la posibilidad (y necesidad) de evaluar los modelos generados reduce la dificultad del punto 1, ya que no es necesario generar el \"mejor modelo posible\" en un solo paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Estimación de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 el problema del diagnóstico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 El problema de la moneda\n",
    "\n",
    "A juzgar por la cantidad de ejemplos sobre monedas arrojadas al aires en libros de estadística y probabilidad, pareciera que las monedas son un elementro central de estas disciplinas, algo de cierto hay. Una de las razones detrás de la ubiquidad de este ejemplo es debida a la cotidianeidad de las monedas, Pero las razones más importante son: el problema puede ser modelado de forma simple, muchos problemas _reales_ son similares, de hecho cualquier problema en donde obtengamos resultados binarios, 0/1, enfermo/sano, spam/no-spam, etc. En definitiva el modelo que veremos a continuación (ejemplificado con monedas) sirve para cualquier situación en la que tengamos que cada valor observado solo puede tomar dos valores mutuamente excluyentes. Dados que estos valores son nominales (ni ordinales ni métricos) y son dos, se les suele llamar binomiales.\n",
    "\n",
    "En el siguiente ejemplo trataremos de determinar el grado en que una moneda está sesgada, es decir que la probabilidad de que caiga cara (o ceca) sea distinta de 0.5. Para ello arrojaremos (computacionalmente) dicha moneda al aire 500 veces. Llevaremos registro del resultado en la variable $y$. Siendo $y$ la cantidad de caras obtenidas en un experimento.\n",
    "\n",
    "Según el teorema de Bayes,\n",
    "\n",
    "$$p(\\theta|y) \\propto p(y|\\theta) p(\\theta)$$\n",
    "\n",
    "Donde $\\theta = 1$ quiere decir 100% cara y $\\theta = 0$ 100% ceca. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definiendo el _a priori_ \n",
    "\n",
    "El _a priori_ lo modelaremos usando una distribución beta.\n",
    "\n",
    "Hay varias razones para usar una distribución beta para este (y otros) problemas. Uno de ellos es que la distribución beta varía entre 0 y 1, de igual forma que nuestra creencias sobre los posibles valores que puede tomar $\\theta$. Otra razón es su versatilidad para expresar distintas situaciones. Supongamos que el experimento de la moneda es realizado por tres personas. Una de ellas dice no saber nada de la moneda por lo tanto _a priori_ todos los valores de $\\theta$ son igualmente probables. La segunda persona desconfía de la moneda, ya que sospecha que es una moneda trucada, por lo tanto considera que está sesgada, pero no sabe si hacia cara o hacia ceca. Por último, la tercer persona asegura que lo más probable es que $\\theta$ tome un valor alrededor de 0.5 ya que según su experiencia así se comportan las monedas. Todas estas situaciones pueden ser modeladas por la distribución beta, como se ve a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "for ind, (a, b) in enumerate([(1, 1), (0.5, 0.5), (20, 20)]):\n",
    "    y = stats.beta.pdf(x, a, b)\n",
    "    plt.subplot(1, 3, ind+1)\n",
    "    plt.plot(x, y, label='a = %s\\nb = %s' % (a, b));\n",
    "    plt.legend(loc=2, fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definiendo el _likelihood_\n",
    "\n",
    "Habiendo definido el _a priori_ veamos ahora el likelihood. Asumiendo que el resultado obtenido al arrojar una moneda no influye en el resultado de posteriores experimentos (es decir los experimentos son independientes entre si) es razonable utilizar como likelihood la distribución binomial.\n",
    "\n",
    "$$p(y|\\theta) = {n \\choose y} \\theta^y (1 - \\theta)^{N−y}$$\n",
    "\n",
    "Donde N es la cantidad total de experimentos (monedas arrojadas al aire) e $y$ es la cantidad de caras obtenidas. A los fines prácticos podríamos simplificar la igualdad anterior y convertirla en una proporcionalidad, eliminando el término {n \\choose y} ya que ese término no depende de $\\theta$ que es lo que nos interesa averiguar. Por lo que podríamos establecer que:\n",
    "\n",
    "$$p(y|\\theta) \\propto \\theta^y (1 - \\theta)^{N−y}$$\n",
    "\n",
    "La elección de esta distribución para modelar nuestro problema es razonable ya que $\\theta$ es la chance de obtener una cara al arrojar una moneda y ese hecho ha ocurrido $y$ veces, de la misma forma $1-\\theta$ es la chance de obtener una seca y lo cual a sido observado $N-y$ veces.\n",
    "\n",
    "Se puede demostrar que siempre que usemos como a priori una función beta y como likelihood una distribución binomial obtendremos como resultado un a posteriori que será una distribución beta con parámetros:\n",
    "\n",
    "$$\\alpha_{posteriori} = \\alpha_{a priori} + y$$\n",
    "$$\\beta_{posteriori} = \\beta_{a priori} + N - y$$\n",
    "\n",
    "Cuando se cumple que dado un _likelihood_ la forma funciona del _a priori_ y la del _a posteriori_ coinciden se dice que el _a priori_ es conjugado con el _likelihood_. Historicamente los problemas en estadística bayesiana estuvieron restringidos al uso de _a prioris_ conjugados, ya que estos garantizan la tratabilidad matemática del problema, es decir garantizan que es posible obtener una expresión analítica para nuestro problema. En el próximo capítulo veremos como técnicas computacionales modernas permiten obtener _a posterioris_ incluso cuando no se usan _a prioris_ conjugados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculando el _a posteriori_\n",
    "\n",
    "Bien, ahora que sabemos como calcular el _a posteriori_, lo único que resta es conseguir los datos. En este ejemplo los datos los obtendremos con un generador de números (pseudo)aleatórios. Exploraremos como cambian las distribuciones _a posteriori_ para distinta cantidad de datos (n_intentos) y veremos el efecto de usar los 3 _a priori_ antes mencionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "dist = stats.beta\n",
    "n_intentos = [0, 1, 2, 3, 4, 5, 8, 15, 50, 500]\n",
    "datos = [0, 1, 1, 1, 1, 2, 4, 5, 13, 170]\n",
    "theta_real = 0.35  # en una situación real este valor es desconocido\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "for k, N in enumerate(n_intentos):\n",
    "    if k == 0:\n",
    "        sx = plt.subplot(4,3, 2)\n",
    "    else:\n",
    "        sx = plt.subplot(4,3, k+3)\n",
    "    plt.xlabel(r\"$\\theta$\") \n",
    "    plt.gca().axes.get_yaxis().set_ticks([])\n",
    "    caras = datos[k]\n",
    "    # a priori uniforme\n",
    "    y = dist.pdf(x, 1 + caras, 1 + N - caras)\n",
    "    plt.plot(x, y, c='b')\n",
    "    plt.fill_between(x, 0, y, color='b', alpha=0.4)\n",
    "    # a priori para una moneda sesgada\n",
    "    y = dist.pdf(x,  0.5 + caras, 0.5 + N - caras)\n",
    "    plt.plot(x, y, c='r')\n",
    "    plt.fill_between(x, 0, y, color='r', alpha=0.4)\n",
    "    # a priori para una moneda no sesgada\n",
    "    y = dist.pdf(x, 20 + caras,  20 + N - caras)\n",
    "    plt.plot(x, y, c='g')\n",
    "    plt.fill_between(x, 0, y, color='g', alpha=0.4)\n",
    "    \n",
    "    plt.vlines(theta_real, 0, 4, color='k', linestyles=\"--\", lw=1)\n",
    "    plt.plot(0, 0, label=\"%d experimentos,\\n %d caras\" % (N, caras), alpha=0)\n",
    "    plt.xlim(0,1)\n",
    "    leg = plt.legend()\n",
    "    leg.get_frame().set_alpha(0.4)\n",
    "    plt.autoscale(tight=True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizando los resultados\n",
    "\n",
    "La primer figura del panel muestra los *a priori*, nuestra estimación del problema dado que no hemos realizado ningún experimento. Las sucesivas nueve figuras muestras las distribuciones *a posteriri* y se indica la cantidad de experimentos y de caras obtenidas.\n",
    "\n",
    "Este ejemplo es realemente ilustrativo en varios aspectos.\n",
    "\n",
    "* Dada una cantidad *suficiente* de datos los resultados tienden a converger sin importar el *a priori* usado\n",
    "* La rapidez con la que los resultados convergen varía. En este ejemplo las curvas azul y roja parecen converger con tan solo 8 experimentos, pero se necesitan más de 50 experimentos para que las tres curvas se muestren similares. Aún con 500 experimentos se observan ligeras diferencias.\n",
    "* La dispersión o ancho de las curvas es una medida de la incertidumbre de un resultado.\n",
    "* Aún cuando $\\frac{2}{1} = \\frac{8}{4}$ son numéricamente iguales tenemos menor incertidumbre en un resultado cuando el número de experimentos es mayor.\n",
    "* Partiendo de los a priori unifome (azul) o sesgado (rojo) y habiendo realizado un solo experimento y observado una sola cara, lo más razonable es pensar que estamos frente a una moneda con dos caras!\n",
    "* La situación cambia drasticamente al ver por primera vez una moneda caer ceca. Ahora lo más probable (dado cualquiera de los tres *a prioris*) es inferir que la moneda no está sesgada. Los valores de $\\theta$ exactamente 0 o 1 se vuelven imposibles.\n",
    "* El a priori no sesgado (verde) es más informativo que los otros dos (la distribución esta más concentrada), por ello se requiere de un número mas grande de experimentos para \"moverlo\".\n",
    "* El a priori uniforme (azul) es lo que se conoce como no informativo. El resultado de un análisis bayesiano usando un _a priori_ no-informativos en general coinciden con los resultados de análisis frecuentistas (en este caso $\\theta = \\frac{y}{N}$). \n",
    "\n",
    "\n",
    "En general solemos estar acostumbrados a pensar una distribución definida por dos parámetros, la media y la desviación alrededor de ese valor medio. Si queremos pensar la distribución beta en esos términos hay dos relaciones que son de utilidad:\n",
    "\n",
    "$$\\alpha = \\mu \\kappa$\n",
    "$$\\beta = (1 − \\mu) \\kappa$$\n",
    "\n",
    "donde $\\mu$ es la media y $\\kappa$ es un parámetro llamado concentración. Por ejemplo si $\\mu=0.5$ y $\\kappa=40$, tenemos que:\n",
    "\n",
    "$$\\alpha = 0.5 * 40 = 20$$\n",
    "$$\\beta = (1-0.5) * 40 = 20$$\n",
    "\n",
    "¿Cuál es el significado de kappa? basicamente lo podemos pensar como la cantidad de experimentos si/no que realizamos dándonos como resultado la media $\\mu$. Es decir el _a priori_ no sesgado (verde) equivale a haber arrojado una moneda 40 veces y haber obtenido como media 0.5. Es decir que si usamos ese _a priori_ recién al observar 40 experimentos si/no, los datos tendrán el mismo peso relativo que el _a priori_, por debajo de este número el _a priori_ contribuye más al resultado final y por encima los datos contribuyen más. El a priori azul (uniforme) equivale a haber observado una moneda caer cara y otra moneda caer ceca ($\\kappa = 2$). Cuando $\\kappa < 2$, la cosa se poco un poco extraña, por ejemplo el _a priori_ sesgado (rojo) equivale a haber observado una sola moneda ($\\kappa = 1$) pero en una especie de _superposición cuántica de estados_! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6  Influencia y elección del _a priori_\n",
    "\n",
    "De los ejemplos anteriores debería quedar claro que los _a priori_ influencian los resultados de nuestros cálculos. Esto tiene total sentido si no fuese así no haría falta incluirlos en el análisis y todo sería más simple (pero no necesariamente mejor). De los ejemplos anteriores también debería quedar claro que a medida que aumentan los datos (como las tiradas de monedas) los resultados son cada vez menos sensibles al _a priori_. De hecho, para una cantidad infinita de datos el _a priori_ no tiene ningún efecto. Exactamente cuantos datos son necesarios para que el efecto del _a priori_ sea despreciable varía según el problema y los modelos usados. En el ejemplo de la moneda se puede ver que 50 experimentos bastan para hacer que dos de los resultados sean prácticamente indistinguibles, pero hacen falta 500 experimentos para que los 3 resultados se vuelvan _casi_ independientes del _a priori_. Esto es así por que los dos primeros _a prioris_ son relativamente _planos_, mientras que el tercer _a priori_ concentra casi toda la probabilidad en una región relativamente pequeña. El tercer a priori no solo considera que el valor más probable de $\\theta$ es 0.5, si no que considera que la mayoría de los otros valores son muy poco probables. ¿Cómo cambiarían los resultados si hubiéramos usado como _a priori_ $\\operatorname{Beta}(\\alpha=2, \\beta=2)$?\n",
    "\n",
    "En casos en que los datos son pocos el _a priori_ tiene un mayor peso relativo en el resultado, esto puede ser ventajoso en caso que contemos con _a prioris_ confiables (basados en información previa proveniente de experimentos, observaciones, teorías o simulaciones). \n",
    "\n",
    "Cuando se discute sobre los _a prioris_ se suele hablar de tres tipos, según la información que contengan:\n",
    "\n",
    "* Informativos: Son *a prioris* que imponen restricciones importantes sobre los valores que pueden tomar los parámetros. Solo deben ser usados en casos que provengan de información previa confiable . Históricamente el uso de _a prioris_ informativos ha sido visto como problemático ya que se los ha asociado con la incorporación de _subjetividades_, diferentes personas pueden usar distintos _a prioris_ debido a que pueden contar con distinta información o con distintas interpretaciones de la misma información. \n",
    "\n",
    "* No-informativos: Son _a prioris_ que restringen los menos posible los valores que pueden tomar los datos. Bajo ciertas condiciones un _a priori_ uniforme es no-informativo (solo los datos aportan información), pero esto no es necesariamente cierto en todos los casos, un a priori de Jeffrey puede ser menos informativo que uno uniforme para ciertos modelos. Obtener este tipo de _a priori_ (dado nuestro problema) no siempre es fácil (o posible). Este tema es algo complejo y no lo veremos en el curso. Para el caso de un likelihood binomial el _a priori_ de Jefrey es el _a priori_ que hemos estado llamando _sesgado_.\n",
    "\n",
    "* Ligeramente informativos: En general los a priori no-informativos no existen (o son difíciles de obtener para problemas complejos). Por lo que varios autores opinan que es mejor hablar (y usar) _a prioris_ ligeramente informativos. La distinción no es solo semántica. Quienes sostienen que es conveniente usar a prioris ligeramente informativos sostienen que la idea general de un a priori es la de regularizar nuestro modelo, es decir restringirlo de forma tal que se evite la posibilidad de obtener valores que carezcan de sentido, por ejemplo números negativos si estamos midiendo distancias o en general valores fuera de ciertos rangos que sabemos imposibles (o que sabemos improbables). \n",
    "\n",
    "Entonces, como elegir los a prioris? Bueno esto depende del problema que pretendemos resolver. Si disponemos de un _a priori_ informativo que creemos confiable entonces lo más razonable es usarlo. La estadística Bayesiana (como cualquier forma de modelado) implica tomar decisiones y la elección del _a priori_ es solo una de ellas, hay muchas otras decisiones (que puede considerarse más o menos *subjetivas*) involucradas en ciencia, empezando por la elección de las preguntas que uno intenta contestar, los datos y métodos que decide usar etc. Empeñarse en que el a priori deba ser lo más objetivo posible es un sinsentido ya que implica ignorar información a nuestra disposición en nombre de un supuesto ideal de objetividad. El objetivo de la ciencia debería ser el de dar respuestas lo más razonables posibles dados los datos a nuestro alcance. La ciencia es objetiva en el sentido que intenta obtener resultados reproducibles e independientes del observador y es subjetiva en el sentido que para lograr ese fin es necesario tomar varias decisiones individuales.\n",
    "\n",
    "En caso de no disponer de a prioris informativos, es buena idea usar a prioris ligeramente informativos. En general los a prioris no-informativos no son una buena idea por que pueden ser difícil (si no imposible) encontrar y en general para la mayoría de los problemas alguna idea (aunque sea vaga) tenemos sobre el problema y es posible incorporar esa información en nuestro análisis via los a prioris.  Además, ¿Dónde está la objetividad en usar un a priori no-informativo que permite valores que sabemos imposibles?\n",
    "\n",
    "Como veremos más adelante la estadística Bayesiana (como cualquier forma de modelado y por extensión cualquier forma de ciencia) es un proceso iterativo en el cual es necesario contrastar los resultados derivados de el modelo generado con los datos que tenemos a dispocisión. En muchos casos eso implicará cambiar partes del modelo, por ejemplo empezar con un a priori ligeramente informativo, para luego usar uno informativo o incluso comparar resultados generando tantos modelos como _a priori_ podamos pensar. \n",
    "\n",
    "Por ultimo, es importante remarcar que es deseable dejar en claro los supuestos de los modelos que usamos en ciencia, especificar un a priori es simplemente especificar nuestros supuestos y someterlos a escrutiño de terceros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Interpretación del  _a posteriori_\n",
    "\n",
    "El resultado de un análisis Bayesiano es siempre una distribución de probabilidad. En el caso de la moneda esto es evidente, y en el caso del diagnostico es menos claro ya que la distribución es discreta y solo puede tomar dos valores.\n",
    "\n",
    "A la hora de comunicar los resultados de un análisis Bayesiano, lo más informativo es reportar la distribución completa, aunque esto no siempre es posible o deseable, por ejemplo el _a posteriori_ de una distribución multidimensional es imposible de dibujar en papel. En general, se suele recurrir a distintas medidas que resumen el _a priori_, por ejemplo reportando la media (o mediana o la moda) de la distribución _a posteriori_. Algo un poco más informativo es reportar además un intervalo de credibilidad. Existen varios criterios para definir intervalos de credibilidad, el que usaremos en este curso (y que también es ampliamente usado en la literatura) es lo que se conoce como intervalo de más alta densidad y nos refereriremos a el por su sigla en ingles, HDI (_highest density interval_ o _highest posterior density interval_). Un HDI es el intervalo que concentra gran parte de la densidad de probabilidad, generalmente el 95%, de tal forma que cualquier punto dentro del intervalo tiene mayor densidad que cualquier punto fuera del intervalo. Para una distribución unimodal, es simplemente el intervalo entre los percentiles 2.5 y 97.5 (asumiendo un HDI de 95%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "post = dist.rvs(9, 4, size=10000)  # un a posteriori sintético\n",
    "\n",
    "def naive_hdi(post):\n",
    "    sns.kdeplot(post)\n",
    "    HDI = np.percentile(post, [2.5, 97.5])\n",
    "    plt.plot(HDI, [0, 0], label='HDI {:.2f} {:.2f}'.format(*HDI), linewidth=8, color='k')\n",
    "    plt.legend(loc=2, fontsize=16);\n",
    "\n",
    "naive_hdi(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una distribucion multimodal, el cáclculo del HDI es ligeramente más complejo. Veamos por ejemplo que sucede si aplicamos la función *naive_hdi* a una mezcla de gaussianas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gauss_a = stats.norm.rvs(loc=4, scale=0.9, size=3000)\n",
    "gauss_b = stats.norm.rvs(loc=-2, scale=1, size=2000)\n",
    "mix_norm = np.concatenate((gauss_a, gauss_b))\n",
    "\n",
    "naive_hdi(mix_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como verán el HDI, calculado de la forma _naive_ incluye valores con baja probabilidad, aproximadamente entre [0, 2]. Para calcular el HDI de forma correcta recurriremos a una función que descargaron al descargar esta notebook *plot_plost*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plot_post import plot_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_post(mix_norm, roundto=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función nos devuelve un HDI (95%) que está compuesto por dos sub-intervalos, además nos devuelve dos modos, uno para cada sub-intervalo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Está nuestra moneda sesgada?\n",
    "\n",
    "Hay veces que no basta con describir el _a posteriori_ si no que se espera que tomemos algún tipo de decisión basados en nuestra inferencia. Por ejemplo responder si la moneda está sesgada, cuando consideramos que $\\theta=0.5$ equivale a no-sesgada. Intuitivamente lo que debemos hacer en este caso es evaluar si el HDI contiene o no el valor que nos interesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_post(post, xlab=r'$\\theta$', roundto=2);  # asumamos que post es nuestro a posteriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso vemos que el valor más probable para $\\theta$ (dados nuestro datos y nuestro modelo) es 0,73 y que el HDI va de 0.44 a 0.92, es decir el intervalo de credibilidad incluye a 0.5. Entonces una posible respuesta sería decir que al parecer lo más probable es que la moneda esté sesgada hacia caras, pero que un valor de 0.5 no puede ser totalmente excluido (según los datos y el modelo).\n",
    "\n",
    "Una versión un poco más formal del análisis anterior es definir primero lo que se conoce como _región de equivalencia práctica_ o ROPE (_Region Of Practical Equivalence_). La razón de definir una ROPE es que es muy dificil que en la práctica obtengamos exactamente el valor 0.5 (estrictamente la probabilidad de un valor exactamente 0.5 es 0). Es por ello, que podríamos definir, para el caso de la moneda, que la ROPE va de 0.45 a 0.55. El ancho de una ROPE es contexto-dependiente y no hay una regla general para construirlo, todo dependerá del problema a resolver.\n",
    "\n",
    "Bien, habiendo establecido la ROPE podemos usar las dos siguientes reglas:\n",
    "\n",
    "* El valor de un parámetro es considerado improbable (poco creible o rechazado) si la totalidad de la ROPE cae por fuera del HDI 95% del parámetro en cuestión.\n",
    "\n",
    "* El valor de un parámetro es aceptado si la ROPE contiene por completo al HDI 95% del parámetro en cuestión\n",
    "\n",
    "Usando *plot_post*, podemos definir una ROPE e indicar un _valor de comparación_ (0.5 en este caso). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_post(dist.rvs(20, 4, size=10000), xlab=r'$\\theta$', roundto=2, ROPE=[0.45, 0.55], comp_val=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*plot_post* nos muestra la ROPE en rojo y en la leyenda el porcentaje de la distribución que cae dentro de la ROPE. En verde nos muestra el _valor de comparación_ y en la leyenda el porcentaje de la distribución que está por debajo y por encima de este valor.\n",
    "\n",
    "En este caso dado que no hay solapamiento entre la ROPE y el HDI 95% podemos decir, según la primer regla antes descripta, que a los fines prácticos determinamos que nuestra moneda no está sesgada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_post(dist.rvs(200, 200, size=10000), xlab=r'$\\theta$', roundto=2, ROPE=[0.45, 0.55]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, y siguiendo la segunda regla, dado que la ROPE contiene por completo al HDI 95% podemos afirmar que la moneda está sesgada. \n",
    "\n",
    "¿Qué sucede cuando el HDI y la ROPE se superponen pero la ROPE solo contiene una porción del HDI? En este caso y dado que no se cumplen ninguna de las 2 reglas arriba especificas, debemos concluir (bajo esas reglas), que no es posible ni afirmar ni negar que la moneda esté sesgada y que probablente necesitemos de más datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_post(post, xlab=r'$\\theta$', roundto=2, ROPE=[0.45, 0.55]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una discusión más detallada del uso de la ROPE y en general del equivalente Bayesiano de la popular técnica frecuentista de _prueba de hipótesis nula_ es posible leer el capítulo 12 de _Doing Bayesian Data analysis_ (segunda edición). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, IPython, scipy, matplotlib, platform\n",
    "print(\"Esta notebook fue creada en una computadora %s corriendo %s y usando:\\nPython %s\\nIPython %s\\nNumPy %s\\nSciPy %s\\nMatplotlib %s\\nSeaborn %s\\n\" % (platform.machine(), ' '.join(platform.linux_distribution()[:2]), sys.version[:5], IPython.__version__, np.__version__, scipy.__version__, matplotlib.__version__, sns.__version__))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
